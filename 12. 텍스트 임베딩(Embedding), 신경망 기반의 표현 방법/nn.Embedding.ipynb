{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "410b9e2d-2c1d-4460-89ae-09caedb4189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56572707-ce72-4626-ba8e-3413853adbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = \"you need to know how to code\"\n",
    "\n",
    "word_set = set(train_data.split())\n",
    "vocab = {tkn: i + 2 for i, tkn in enumerate(word_set)}\n",
    "vocab[\"<unk>\"] = 0\n",
    "vocab[\"<pad>\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a9ea90-b2fd-4faa-8710-0ba2043f5bd3",
   "metadata": {},
   "source": [
    "- num_embeddings: 임베딩 할 단어 수\n",
    "- embedding_dim: 임베딩 벡터 차원\n",
    "- padding_idx: 패딩을 위한 토큰 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7cedc8-0cb0-4e04-90b1-30538708e51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(\n",
    "    num_embeddings=len(vocab), embedding_dim=3, padding_idx=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209d30d6-3b71-47bb-9e58-d39c291bef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.2850,  0.6503,  0.4057],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [-1.0173, -3.1059, -0.9376],\n",
       "        [ 1.2750,  1.4486, -0.6100],\n",
       "        [-1.2053, -0.0387, -1.4802],\n",
       "        [ 2.3452,  0.7615,  0.1973],\n",
       "        [ 2.2656,  0.1313, -1.1834],\n",
       "        [-0.8589,  0.4082, -0.1675]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20eb508f-ad5b-48c2-9edd-3ce480d6e882",
   "metadata": {},
   "source": [
    "# 사전 훈련된 워드 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076eb75-4031-4fe3-b8d3-23aa9b591b83",
   "metadata": {},
   "source": [
    "훈련 데이터가 적다면 nn.Embedding으로 해당 문제에 충분히 특화된 임베딩 벡터를 만드는 게 쉽지 않다. 이 경우 문제에 특화된 것은 아니지만 보다 일반적이고 보다 많은 훈련 데이터로 이미 Word2Vec이나 GloVE 등으로 학습된 임베딩 벡터를 사용하는 게 성능에 좋을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b9f4f-be9d-4bbc-aabe-8e106dcffa4c",
   "metadata": {},
   "source": [
    "## 사전 훈련된 임베딩을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "415d7e7c-bc03-45c7-a2e3-30f955f7c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26945c90-3ba9-4787-9078-1705f4c46209",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"nice great best amazing\",\n",
    "    \"stop lies\",\n",
    "    \"pitiful nerd\",\n",
    "    \"excellent work\",\n",
    "    \"supreme quality\",\n",
    "    \"bad\",\n",
    "    \"highly respectable\",\n",
    "]\n",
    "y_train = [1, 0, 0, 1, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bffc349-049b-449b-9a8a-87dffe07a1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['nice', 'great', 'best', 'amazing'],\n",
       " ['stop', 'lies'],\n",
       " ['pitiful', 'nerd'],\n",
       " ['excellent', 'work'],\n",
       " ['supreme', 'quality'],\n",
       " ['bad'],\n",
       " ['highly', 'respectable']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sentences = [sent.split() for sent in sentences]\n",
    "tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27739a80-7029-4d52-9462-b6ce6556cf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       " Counter({'nice': 1,\n",
       "          'great': 1,\n",
       "          'best': 1,\n",
       "          'amazing': 1,\n",
       "          'stop': 1,\n",
       "          'lies': 1,\n",
       "          'pitiful': 1,\n",
       "          'nerd': 1,\n",
       "          'excellent': 1,\n",
       "          'work': 1,\n",
       "          'supreme': 1,\n",
       "          'quality': 1,\n",
       "          'bad': 1,\n",
       "          'highly': 1,\n",
       "          'respectable': 1}))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = []\n",
    "for sent in tokenized_sentences:\n",
    "    for word in sent:\n",
    "        word_list.append(word)\n",
    "\n",
    "word_counts = Counter(word_list)\n",
    "len(word_counts), word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48486929-0600-414d-b7bb-6f3117cee6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nice',\n",
       " 'great',\n",
       " 'best',\n",
       " 'amazing',\n",
       " 'stop',\n",
       " 'lies',\n",
       " 'pitiful',\n",
       " 'nerd',\n",
       " 'excellent',\n",
       " 'work',\n",
       " 'supreme',\n",
       " 'quality',\n",
       " 'bad',\n",
       " 'highly',\n",
       " 'respectable']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "056bf887-6a6e-4690-b451-939858267587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index = {}\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<UNK>\"] = 1\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "    word_to_index[word] = index + 2\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9783c62-add2-4d82-8551-a00c467b2e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<UNK>': 1,\n",
       " 'nice': 2,\n",
       " 'great': 3,\n",
       " 'best': 4,\n",
       " 'amazing': 5,\n",
       " 'stop': 6,\n",
       " 'lies': 7,\n",
       " 'pitiful': 8,\n",
       " 'nerd': 9,\n",
       " 'excellent': 10,\n",
       " 'work': 11,\n",
       " 'supreme': 12,\n",
       " 'quality': 13,\n",
       " 'bad': 14,\n",
       " 'highly': 15,\n",
       " 'respectable': 16}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f376904-1db7-4c50-a9f8-aa0aead25523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def texts_to_sequences(tokenized_X_data, word_to_index):\n",
    "    encoded_X_data = []\n",
    "    for sent in tokenized_X_data:\n",
    "        index_sequences = []\n",
    "        for word in sent:\n",
    "            try:\n",
    "                index_sequences.append(word_to_index[word])\n",
    "            except KeyError:\n",
    "                index_sequences.append(word_to_index[\"<UNK>\"])\n",
    "        encoded_X_data.append(index_sequences)\n",
    "    return encoded_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68bba1b-e569-4bc9-b866-161bbe68be49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 5], [6, 7], [8, 9], [10, 11], [12, 13], [14], [15, 16]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = texts_to_sequences(tokenized_sentences, word_to_index)\n",
    "X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1326f8ba-9bab-4abe-b7fa-4248df4207e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(len(l) for l in X_encoded)\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d753cda8-733f-4c1f-9ec6-5addc4a14cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sentences, max_len):\n",
    "    features = np.zeros((len(sentences), max_len), dtype=int)\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if len(sentence) != 0:\n",
    "            features[index, : len(sentence)] = np.array(sentence)[:max_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffcd2b1b-3789-463a-919f-ec92824a4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_encoded, max_len=max_len)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4247334c-05c4-4f4b-a8de-ca6586a7098b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  3,  4,  5],\n",
       "       [ 6,  7,  0,  0],\n",
       "       [ 8,  9,  0,  0],\n",
       "       [10, 11,  0,  0],\n",
       "       [12, 13,  0,  0],\n",
       "       [14,  0,  0,  0],\n",
       "       [15, 16,  0,  0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9627775-cd05-4490-8334-92d0769ad614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f24d09f8-2ffc-4d8a-8cb9-53967ccd1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(embedding_dim * max_len, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        flattened = self.flatten(embedded)\n",
    "        output = self.fc(flattened)\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19c413e9-f0a8-4041-9e7a-08ba8c54ed4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "695c30b7-e343-4bfb-932f-7516993a1cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "simple_model = SimpleModel(vocab_size, embedding_dim).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4556e36-8856-4edc-a5ea-70cee20483db",
   "metadata": {},
   "source": [
    "출력츠엥 로지스틱 회귀를 이용한 이진 분류를 푸는 모델이므로 바이너리 크로스엔트로피 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3892050-15a1-42c6-a922-f506f63ca6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(simple_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cf40459-2514-48a4-be58-60d7168de4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c85ded90-a012-44d3-bc77-c7ed1dcc79fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a451e4b0-7d42-4309-b812-cd3030187f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6253615021705627\n",
      "Epoch 2, Loss: 0.48311108350753784\n",
      "Epoch 3, Loss: 0.3619559705257416\n",
      "Epoch 4, Loss: 0.27890700101852417\n",
      "Epoch 5, Loss: 0.226105198264122\n",
      "Epoch 6, Loss: 0.1928638219833374\n",
      "Epoch 7, Loss: 0.17089177668094635\n",
      "Epoch 8, Loss: 0.15466190874576569\n",
      "Epoch 9, Loss: 0.1408553272485733\n",
      "Epoch 10, Loss: 0.127839133143425\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for inputs, targets in train_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = simple_model(inputs).view(-1)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4214ddad-3f5e-4f5a-a56e-1b6bfbc965e9",
   "metadata": {},
   "source": [
    "## 사전 훈련된 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3583ee37-d2c0-4520-b8eb-f01026954bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    \"../model/GoogleNews-vectors-negative300.bin.gz\", binary=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12720abd-3fad-45aa-ba02-f6ebc2c561e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 300)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e13ee120-6461-46aa-8a96-4c76aa0584c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(word):\n",
    "    if word in word2vec_model:\n",
    "        return word2vec_model[word]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f8cc72-035a-40a5-8577-554269a6f69b",
   "metadata": {},
   "source": [
    "단어 집합으로부터 단어를 한개씩 호출해 word2vec_model에서 단어의 임베딩 벡터값을 가져온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "af0b7744-acd0-4d32-aa5d-45daccfeabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, i in word_to_index.items():\n",
    "    if i > 2:\n",
    "        temp = get_vector(word)\n",
    "        if temp is not None:\n",
    "            embedding_matrix[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a61aa4eb-28b4-4cef-9e99-cfd21f771b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedEmbeddingModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.embedding.weight = nn.Parameter(\n",
    "            torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "        )\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(embedding_dim * max_len, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        flattened = self.flatten(embedded)\n",
    "        output = self.fc(flattened)\n",
    "        return self.sigmoid(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f86a95f-a939-4550-9e82-2e2de9df6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding_model = PretrainedEmbeddingModel(vocab_size, 300).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c98eee6-e03a-43dd-a436-a7add7316d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = Adam(pretrained_embedding_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ede55f1e-5940-43cc-91ef-9f06ba2c5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train, dtype=torch.long), torch.tensor(y_train, dtype=torch.float32)\n",
    ")\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12f8f164-3979-4b01-8621-9029fdee5841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6374518275260925\n",
      "Epoch 2, Loss: 0.5786298513412476\n",
      "Epoch 3, Loss: 0.5203221440315247\n",
      "Epoch 4, Loss: 0.46565109491348267\n",
      "Epoch 5, Loss: 0.4154130816459656\n",
      "Epoch 6, Loss: 0.369762122631073\n",
      "Epoch 7, Loss: 0.3286037743091583\n",
      "Epoch 8, Loss: 0.29172682762145996\n",
      "Epoch 9, Loss: 0.2588597238063812\n",
      "Epoch 10, Loss: 0.22969816625118256\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for inputs, targets in train_dataloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = pretrained_embedding_model(inputs).view(-1)\n",
    "\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
