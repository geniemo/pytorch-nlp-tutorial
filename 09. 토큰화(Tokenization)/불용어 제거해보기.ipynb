{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5f5efc-0da6-4354-acaa-d5a03779491e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3213ee2-26f9-459e-a483-4e8e61f8d5d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,\n",
       " ['i',\n",
       "  'me',\n",
       "  'my',\n",
       "  'myself',\n",
       "  'we',\n",
       "  'our',\n",
       "  'ours',\n",
       "  'ourselves',\n",
       "  'you',\n",
       "  \"you're\"])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_list = stopwords.words(\"english\")\n",
    "len(stop_words_list), stop_words_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abaa746b-12c3-43b8-9339-f4b2636e1667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거 전: ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
      "제거 후: ['Family', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n"
     ]
    }
   ],
   "source": [
    "example = \"Family is not an important thing. It's everything.\"\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "word_tokens = word_tokenize(example)\n",
    "\n",
    "result = []\n",
    "for word in word_tokens:\n",
    "    if word not in stop_words:\n",
    "        result.append(word)\n",
    "\n",
    "print(f\"제거 전: {word_tokens}\")\n",
    "print(f\"제거 후: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff50a2a-ec5d-484b-b26c-54e0d2ca026d",
   "metadata": {},
   "source": [
    "한국어에서 불용어 제거 시 조사나 접속사 같은 단어들 뿐만 아니라 명사, 형용사 같은 단어들 중에서 불용어로서 제거하고 싶은 단어들이 생기기도 한다. 결국 사용자가 직접 불용어 사전을 만들게 되는 경우가 많다.\n",
    "\n",
    "아래의 불용어는 실습을 위해 임의 선정한 것으로 실제 의미 있는 선정 기준이 아니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b6dbfb-d8a4-4287-8fc8-746051188ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거 전: ['고기', '를', '아무렇게나', '구', '우려', '고', '하면', '안', '돼', '.', '고기', '라고', '다', '같은', '게', '아니거든', '.', '예컨대', '삼겹살', '을', '구울', '때', '는', '중요한', '게', '있지', '.']\n",
      "제거 후: ['고기', '하면', '.', '고기', '라고', '다', '아니거든', '.', '예컨대', '삼겹살', '을', '중요한', '있지', '.']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "\n",
    "example = (\n",
    "    \"고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든.\"\n",
    "    \" 예컨대 삼겹살을 구울 때는 중요한 게 있지.\"\n",
    ")\n",
    "stop_words = set(\"를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는\".split())\n",
    "\n",
    "word_tokens = okt.morphs(example)\n",
    "result = [word for word in word_tokens if not word in stop_words]\n",
    "\n",
    "print(f\"제거 전: {word_tokens}\")\n",
    "print(f\"제거 후: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb96b3-9384-4e92-8df1-185b2e432812",
   "metadata": {},
   "source": [
    "https://www.ranks.nl/stopwords/korean\n",
    "\n",
    "에서 보편적 한국어 불용어 리스트를 볼 수 있다. 하지만 여전히 절대적이진 않다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
